# Pinecone RAG System

Un sistema de Retrieval-Augmented Generation (RAG) que utiliza Pinecone como base de datos vectorial y LangChain para el procesamiento de documentos e interacciones con IA.

## ğŸš€ CaracterÃ­sticas

- **Carga de Documentos**: Soporte para mÃºltiples formatos de archivo (PDF, DOCX, TXT, PPTX, XLSX, XLS)
- **Procesamiento Inteligente**: DivisiÃ³n automÃ¡tica de documentos en chunks con overlap configurable
- **Base de Datos Vectorial**: IntegraciÃ³n con Pinecone para almacenamiento y bÃºsqueda de embeddings
- **IA Conversacional**: IntegraciÃ³n con OpenAI GPT-4 para respuestas basadas en contexto
- **ConfiguraciÃ³n Flexible**: ParÃ¡metros personalizables para chunk size y overlap

## ğŸ“‹ Requisitos

- Python 3.13 o superior
- Cuenta de Pinecone
- API Key de OpenAI

## ğŸ› ï¸ InstalaciÃ³n

1. **Clona el repositorio**:
   ```bash
   git clone <repository-url>
   cd pinecone-rag
   ```

2. **Instala las dependencias**:
   ```bash
   pip install -e .
   ```

3. **Instala las dependencias de desarrollo** (opcional):
   ```bash
   pip install -e ".[dev]"
   ```

4. **Configura las variables de entorno**:
   Crea un archivo `.env` en la raÃ­z del proyecto con las siguientes variables:
   ```env
   PINECONE_API_KEY=tu_api_key_de_pinecone
   BTECH_OPENAI_API_KEY_MERMAID=tu_api_key_de_openai
   ```

## ğŸ—ï¸ Estructura del Proyecto

```
pinecone-rag/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ llm_config.py          # ConfiguraciÃ³n de LLM y prompts
â”‚   â”œâ”€â”€ loader/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ docs_loader.py         # Cargador de documentos
â”‚   â””â”€â”€ pinecone_db_services/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py              # ConfiguraciÃ³n de Pinecone
â”‚       â””â”€â”€ add_docs.py            # Servicios para agregar documentos
â”œâ”€â”€ docs/                          # Documentos de ejemplo
â”œâ”€â”€ main.py                        # Punto de entrada principal
â”œâ”€â”€ pyproject.toml                 # ConfiguraciÃ³n del proyecto
â””â”€â”€ README.md                      # Este archivo
```

## ğŸ“– Uso

### 1. Cargar Documentos

El sistema puede cargar documentos desde un directorio o archivo individual:

```python
from app.loader.docs_loader import load_documents_from_directory

# Cargar desde un directorio
documents = load_documents_from_directory(
    directory_path="./docs",
    chunk_size=800,
    chunk_overlap=100
)

# Cargar un archivo individual
documents = load_documents_from_directory(
    directory_path="./docs/documento.pdf",
    chunk_size=800,
    chunk_overlap=100
)
```

### 2. Agregar Documentos a Pinecone

```python
from app.pinecone_db_services.add_docs import add_docs_into_vector_store

# Agregar documentos al vector store
success = add_docs_into_vector_store(documents)
if success:
    print("Documentos agregados exitosamente")
```

### 3. Realizar Consultas RAG

```python
from app.ai.llm_config import State, retrieve, generate

# Crear un estado para la consulta
state = State(question="Â¿CuÃ¡l es la experiencia de Reynaldo Suarez?")

# Recuperar documentos relevantes
state = retrieve(state)

# Generar respuesta
state = generate(state)

print(f"Respuesta: {state.answer}")
```

## âš™ï¸ ConfiguraciÃ³n

### ParÃ¡metros de Chunking

- **chunk_size**: TamaÃ±o de cada chunk (por defecto: 800)
- **chunk_overlap**: Overlap entre chunks (por defecto: 100)

### ConfiguraciÃ³n de Pinecone

- **Index Name**: `langchain-test-index` (configurable en `app/pinecone_db_services/config.py`)
- **Dimension**: 3072 (para embeddings de OpenAI)
- **Metric**: Cosine similarity
- **Cloud**: AWS us-east-1

### Modelos de IA

- **Embeddings**: `text-embedding-3-large` (OpenAI)
- **LLM**: `gpt-4o` (OpenAI)

## ğŸ“ Formatos de Archivo Soportados

- **PDF**: Documentos PDF
- **DOCX**: Documentos de Word
- **TXT**: Archivos de texto plano
- **PPTX**: Presentaciones de PowerPoint
- **XLSX/XLS**: Hojas de cÃ¡lculo de Excel

## ğŸ”§ Desarrollo

### Herramientas de Desarrollo

El proyecto incluye las siguientes herramientas de desarrollo:

- **Black**: Formateador de cÃ³digo
- **Ruff**: Linter y formateador
- **Codespell**: Verificador de ortografÃ­a
- **Pre-commit**: Hooks de pre-commit

### Ejecutar Herramientas de Desarrollo

```bash
# Formatear cÃ³digo
black .

# Linting
ruff check .

# Verificar ortografÃ­a
codespell .

# Instalar hooks de pre-commit
pre-commit install
```

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ†˜ Soporte

Si tienes problemas o preguntas:

1. Revisa la documentaciÃ³n
2. Busca en los issues existentes
3. Crea un nuevo issue con detalles del problema

## ğŸ”„ Roadmap

- [ ] Interfaz web para consultas
- [ ] Soporte para mÃ¡s formatos de archivo
- [ ] OptimizaciÃ³n de embeddings
- [ ] Sistema de cachÃ© para consultas frecuentes
- [ ] MÃ©tricas y monitoreo